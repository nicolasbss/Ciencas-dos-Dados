{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "    \n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: @nic_stegmann\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Netflix'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "O critério primeiramente estabelecido para definir a relevância dos tweets para a Netflix foi: \"O tweet fala sobre a existência ou falta de algum produto no catálogo da Netflix?\" caso a resposta para essa pergunta fosse sim, o tweet foi classificado como importante.\n",
    "\n",
    "Esse critério foi estabelecido pois julgou-se importante para a empresa ter noção de quais produtos do catálogo as pessoas mais sentem faltam ou apreciam no catálogo, para que estes sejam valorizados conforme esta noção. Assim, os passos adiantes procuram criar o classificador naive bayes conforme este critério"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os tweets para o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "não    0.826667\n",
      "sim    0.173333\n",
      "Name: classificador, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import mpmath\n",
    "\n",
    "#lendo o dataframe\n",
    "data = pd.read_excel(\"Netflix.xlsx\")\n",
    "\n",
    "#checando a probabilidade de um tweet ser relevante ou não\n",
    "prob_relevancia = data.classificador.value_counts(True)\n",
    "print(prob_relevancia)\n",
    "\n",
    "def remove_pontuação(frase, lista_nova):\n",
    "    for palavra in frase:\n",
    "        for caractere in palavra:\n",
    "            if caractere in pontuação:\n",
    "                palavra = palavra.replace(caractere, \"\")\n",
    "        lista_nova.append(palavra)\n",
    "\n",
    "#criando parâmetros para retirar todas as pontuações das palavras\n",
    "tweets = np.sum(data.Treinamento + \" \")\n",
    "tweets = tweets.split()\n",
    "pontuação = list(string.punctuation)\n",
    "\n",
    "#removendo pontuação de todas as palavras\n",
    "palavras = []\n",
    "remove_pontuação(tweets, palavras)\n",
    "    \n",
    "#criando um uma lista contendo apenas pavlaras que aparecem nos posts relevantes\n",
    "t_relevantes = np.sum(data[data.classificador == \"sim\"].Treinamento + \" \")\n",
    "t_relevantes = t_relevantes.split()\n",
    "\n",
    "#criando um uma lista contendo apenas pavlaras que aparecem nos posts não relevantes\n",
    "t_nrelevantes = np.sum(data[data.classificador == \"não\"].Treinamento + \" \")\n",
    "t_nrelevantes = t_nrelevantes.split()\n",
    "\n",
    "#removendo pontuação das palavras relevantes e não relevantes\n",
    "p_relevantes = []\n",
    "p_nrelevantes = []\n",
    "remove_pontuação(t_relevantes, p_relevantes)\n",
    "remove_pontuação(t_nrelevantes, p_nrelevantes)\n",
    "\n",
    "#salvando em uma variável a quantidade de palavras diferentes\n",
    "n_palavras = len(palavras)\n",
    "n_palavrasr = len(p_relevantes)\n",
    "n_palavrasnr = len(p_nrelevantes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando as probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunaaux_rel = pd.Series(p_relevantes)\n",
    "colunaaux_nrel = pd.Series(p_nrelevantes)\n",
    "\n",
    "prob_prel = colunaaux_rel.value_counts()\n",
    "prob_pnrel = colunaaux_nrel.value_counts()\n",
    "\n",
    "prel_laplace = pd.Series((prob_prel + 1) / (n_palavrasr + n_palavras))\n",
    "pnrel_laplace = pd.Series((prob_pnrel + 1) / (n_palavrasnr + n_palavras))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.read_excel(\"Netflix.xlsx\", \"Teste\")\n",
    "\n",
    "lista_teste = list(teste.Teste)\n",
    "lista_tweets = []\n",
    "\n",
    "\n",
    "for tweet in lista_teste:\n",
    "    for caractere in tweet:\n",
    "        if caractere in pontuação:\n",
    "            tweet = tweet.replace(caractere, \"\")\n",
    "    lista_tweets.append(tweet)\n",
    "\n",
    "def Probabilidade_frase(lista_tweets, prob1, prob2, prob3):\n",
    "    lista_probabilidade = []\n",
    "    for tweets in lista_tweets:\n",
    "        p_frase = 1\n",
    "        for palavra in tweets:\n",
    "            if palavra in prob1.index:\n",
    "                p_frase = p_frase * prob1[palavra] * prob2\n",
    "            else:\n",
    "                p_frase = 1/(prob3 + n_palavras) * p_frase * prob2\n",
    "        lista_probabilidade.append(p_frase)\n",
    "    return lista_probabilidade\n",
    "\n",
    "teste_r = Probabilidade_frase(lista_tweets, prob_prel, prob_relevancia[1], n_palavrasr)\n",
    "teste_nr = Probabilidade_frase(lista_tweets, prob_pnrel, prob_relevancia[0], n_palavrasnr)\n",
    "\n",
    "\n",
    "def Comparador(teste_r, teste_nr):\n",
    "    resposta = []\n",
    "    for i in range(len(teste_r)):\n",
    "        if teste_r[i] > teste_nr[i]:\n",
    "            resposta.append(\"sim\")\n",
    "        elif teste_r[i] < teste_nr[i]:\n",
    "            resposta.append(\"não\")\n",
    "        elif teste_r[i] == teste_nr[i]:\n",
    "            resposta.append(\"seila\")\n",
    "    return resposta\n",
    "    \n",
    "respostas = Comparador(teste_r, teste_nr)\n",
    "data = {\"tweets\" : lista_teste, \"classificador\": teste.classificador, \"respostas\": respostas}\n",
    "\n",
    "tabela_testes = pd.DataFrame(data, columns = [\"tweets\", \"classificador\", \"respostas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negativo verdadeiro    0.895\n",
       "negativo falso         0.105\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificação = []\n",
    "for i in range(len(respostas)):\n",
    "    if teste.classificador[i] == respostas[i]:\n",
    "        if respostas[i] == \"não\":\n",
    "            verificação.append(\"negativo verdadeiro\")\n",
    "        elif respostas[i] == \"sim\":\n",
    "            verificação.append(\"positivo verdadeiro\")\n",
    "    \n",
    "    elif teste.classificador[i] != respostas[i]:\n",
    "        if respostas[i] == \"não\":\n",
    "            verificação.append(\"negativo falso\")\n",
    "        elif respostas[i] == \"sim\":\n",
    "            verificação.append(\"positivo falso\")\n",
    "            \n",
    "            \n",
    "verificaçãoS = pd.Series(verificação)\n",
    "porcentagem = verificaçãoS.value_counts(True)\n",
    "porcentagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão do primeiro teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos resultados obtidos na verificação do primeiro classificador Naive-bayes nota-se que há uma relação muito forte entre a P(relevante) ou P(irrelevante) e os resultados obtidos pelo classificador. Isso pode ser explicado conforme a relação matemática utilizada pelo classificador que é: P(relevancia|tweet) = (P(palavras|relevancia) * P(relevancia))/P(tweet). Como o critério estabelecido na primeira utilização do classificador indicava um P(relevante) muito menor do que P(não-relevância) e o programa não foi alimentado com uma base de dados suficientemente grande para gerar respostas precisas, o classificador resultou em apenas classificações negativas.\n",
    "\n",
    "Tendo isso em mente, foi proposto um segundo critério de classificação de relevancia para os tweets: \"O tweet fala sobre a existência de um filme no catálogo ou sobre a conta que utiliza para acessar os produtos da Netflix?\". Tal critério foi considerado relevante pois daria a noção para a empresa sobre quantas pessoas utilizam contas próprias na netflix e quantas pessoas usam contas de outras pessoas para acessar seus produtos, para que assim fosse possível calcular qual a receita que teriam se todas essas pessoas tivessem que utilizar contas próprias, além dos benefícios já citados sobre saber quais filmes são mais citados pelas pessoas.\n",
    "\n",
    "Assim, foi criado outro classificador, descrito abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os tweets para o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "não    0.646667\n",
      "sim    0.353333\n",
      "Name: classificador, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#lendo o dataframe\n",
    "data2 = pd.read_excel(\"Netflix(1).xlsx\")\n",
    "\n",
    "#checando a probabilidade de um tweet ser relevante ou não\n",
    "prob_relevancia2 = data2.classificador.value_counts(True)\n",
    "print(prob_relevancia2)\n",
    "\n",
    "\n",
    "#criando parâmetros para retirar todas as pontuações das palavras\n",
    "tweets2 = np.sum(data2.Treinamento + \" \")\n",
    "tweets22 = tweets2.split()\n",
    "pontuação2 = list(string.punctuation)\n",
    "\n",
    "#removendo pontuação de todas as palavras\n",
    "palavras2 = []\n",
    "remove_pontuação(tweets2, palavras2)\n",
    "    \n",
    "#criando um uma lista contendo apenas pavlaras que aparecem nos posts relevantes\n",
    "t_relevantes2 = np.sum(data2[data2.classificador == \"sim\"].Treinamento + \" \")\n",
    "t_relevantes2 = t_relevantes2.split()\n",
    "\n",
    "#criando um uma lista contendo apenas pavlaras que aparecem nos posts não relevantes\n",
    "t_nrelevantes2 = np.sum(data2[data2.classificador == \"não\"].Treinamento + \" \")\n",
    "t_nrelevantes2 = t_nrelevantes2.split()\n",
    "\n",
    "#removendo pontuação das palavras relevantes e não relevantes\n",
    "p_relevantes2 = []\n",
    "p_nrelevantes2 = []\n",
    "remove_pontuação(t_relevantes2, p_relevantes2)\n",
    "remove_pontuação(t_nrelevantes2, p_nrelevantes2)\n",
    "\n",
    "#salvando em uma variável a quantidade de palavras diferentes\n",
    "n_palavras2 = len(palavras2)\n",
    "n_palavrasr2 = len(p_relevantes2)\n",
    "n_palavrasnr2 = len(p_nrelevantes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando as probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colunaaux_rel2 = pd.Series(p_relevantes2)\n",
    "colunaaux_nrel2 = pd.Series(p_nrelevantes2)\n",
    "\n",
    "prob_prel2 = colunaaux_rel2.value_counts()\n",
    "prob_pnrel2 = colunaaux_nrel2.value_counts()\n",
    "\n",
    "prel_laplace2 = pd.Series((prob_prel2 + 1) / (n_palavrasr2 + n_palavras2))\n",
    "pnrel_laplace2 = pd.Series((prob_pnrel2 + 1) / (n_palavrasnr2 + n_palavras2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2 = pd.read_excel(\"Netflix(1).xlsx\", \"Teste\")\n",
    "\n",
    "lista_teste2 = list(teste2.Teste)\n",
    "lista_tweets2 = []\n",
    "\n",
    "\n",
    "for tweet in lista_teste:\n",
    "    for caractere in tweet:\n",
    "        if caractere in pontuação:\n",
    "            tweet = tweet.replace(caractere, \"\")\n",
    "    lista_tweets2.append(tweet)\n",
    "    \n",
    "teste_r2 = Probabilidade_frase(lista_tweets2, prob_prel2, prob_relevancia2[1], n_palavrasr2)\n",
    "teste_nr2 = Probabilidade_frase(lista_tweets2, prob_pnrel2, prob_relevancia2[0], n_palavrasnr2)\n",
    "\n",
    "respostas2 = Comparador(teste_r2, teste_nr2)\n",
    "data2 = {\"tweets\" : lista_teste2, \"classificador\": teste2.classificador, \"respostas\": respostas2}\n",
    "\n",
    "\n",
    "tabela_testes2 = pd.DataFrame(data2, columns = [\"tweets\", \"classificador\", \"respostas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negativo verdadeiro    0.628141\n",
       "negativo falso         0.201005\n",
       "positivo falso         0.150754\n",
       "positivo verdadeiro    0.020101\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificação2 = []\n",
    "for i in range(len(respostas2)):\n",
    "    if teste2.classificador[i] == respostas2[i]:\n",
    "        if respostas2[i] == \"não\":\n",
    "            verificação2.append(\"negativo verdadeiro\")\n",
    "        elif respostas2[i] == \"sim\":\n",
    "            verificação2.append(\"positivo verdadeiro\")\n",
    "    \n",
    "    elif teste2.classificador[i] != respostas2[i]:\n",
    "        if respostas2[i] == \"não\":\n",
    "            verificação2.append(\"negativo falso\")\n",
    "        elif respostas2[i] == \"sim\":\n",
    "            verificação2.append(\"positivo falso\")\n",
    "            \n",
    "            \n",
    "verificaçãoS2 = pd.Series(verificação2)\n",
    "porcentagem2 = verificaçãoS2.value_counts(True)\n",
    "porcentagem2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Após desenvolvido o classificador naive-bayes, é de grande importância a análise de certos tópicos relacionados ao projeto.\n",
    "\n",
    "Primeiramente, é importante perceber que o resultado da verificação do projeto está intimamente relacionado ao critério de classificação da relevância de posts. Isso se dá pois caso a probabilidade de um tweet ser relevante ou não seja muito maior do que o contrário, a probabilidade de o classificador indicar um resultado equivocado é muito grande, conforme observado na elaboração do primeiro classificador. Isso é constatado na relação matemática utilizada pelo classificador que é: P(relevancia|tweet) = (P(palavras|relevancia) * P(relevancia))/P(tweet). Nos nossos cálculos descartamos o divisor pois ele é igual para ambas categoriase portanto não é relevante na comparação.\n",
    "\n",
    "Assim, conforme a relação expressa acima, chegamos em uma outra conclusão: Tweets contendo ironia ou dupla negação tendem a ser classificados equivocadamente. Isso se deve ao fato de que a relação matemática classifica as frases de acordo com um princípio de independência das probabilidades de cada palavra aparecerem nos tweets relevantes e irrelevantes e sendo assim, ela não leva em consideração o contexto em que são utilizados. Dessa forma, mensagens que sarcásticas tendem a ter uma discrepancia em relação a sua relevancia verdadeira.\n",
    "\n",
    "O projeto aqui desenvolvido, entretanto, possui um grande potêncial de crescimento. Conforme já mencionado na explicação dos critérios selecionados é possível, através desta pesquisa, perceber qual a tendência do mercado em relação aos produtos no catálogo da empresa e em relação ao uso indevido de contas. A partir destes dados, é possível maximizar a receita da empresa através de mudanças estratégicas nas duas areas pesquisadas no projeto. Logo, é importante que este projeto seja desenvolvido posteriormente.\n",
    "\n",
    "Para isso, é necessário que a base de dados seja constantemente alimentada, pois assim, o programa se tornará cada vez mais preciso. Entrtanto, isso nao deve ser feito ultilizando o classificador em novos tweets, pois desse modo o programa continuará realizando comparações com os mesmos parâmetros para estimar a probabilidade de relevância do tweet. De maneira correta, o programa deve ser alimentado com classificações com os mesmos critérios, mas realizadas por algo externo ao programa. Desse modo, conforme novas referencias forem dadas ao programa mais preciso ele se tornará, pois os padrões de frequência das palavras em tweets relevantes ou não se tornará cada vez mais claro.\n",
    "\n",
    "O classificador aqui desenvolvido, nesse sentido, pode ser utilizado para diversos fins. Por sua capacidade de análise de padrões já decorrida previamente, ele é capaz de auxiliar um engenheiro em diversos cenários, como por exemplo ná analise de falhas no comportamento de manipuladores robóticos ou até mesmo a classificação de palavras como pertecentes as mais variadas línguas do mundo.\n",
    "\n",
    "Para melhorar o classificador aqui montado, é possível adotar os seguintes procedimentos entre outros:\n",
    "1. Considerar palavras derivadas do mesmo radical como uma só, para que suas aparições sejam consideradas mais vezes, como por exemplo as palavras gostei, gostaram, gostar.\n",
    "2. Excluir palavras que não contribuem para a categorização da frase, como por exemplo, \"da\", \"do\", \"a\" e \"o\".\n",
    "referencias : https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
